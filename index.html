<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AlexDiRobot</title>
<style>
  body {
    font-family: 'Arial', sans-serif;
    background-color: #ffffff;
    color: #000000;
    margin: 0;
    padding: 0;
  }
  .container {
    width: 80%;
    margin: auto;
    overflow: hidden;
  }
  header {
    background: #222;
    color: rgb(255, 255, 255);
    padding: 20px;
    text-align: center;
  }
  h2 {
    border-bottom: 1px solid #555;
    padding-bottom: 5px;
  }
  p {
    font-size: 16px;
    line-height: 1.6em;
  }
  section {
    margin: 20px 0;
  }
</style>
</head>
<body>
  <header>
    <h1>AlexDiBot<br>Grocery Prices Robot</h1>
  </header>
  <div class="container">
    <section id="what-is-this">
      <h2>What is this?</h2>
      <p>This is a robot that gets daily data from leading grocery shops for a University project.</p>
      <p><b>Why?</b><br>
      Some people (like me) prefer to make a budget using a spreadsheet and the website can be hard to navigate quickly and copy price info each week. This makes budgeting a breeze. Also this data is useful for tracking prices overtime.</p>
      <p>- Data is free and avaliable in CSV (can open this in excel or google sheets) file download.</p>
      <p>- API endpoints are coming soon.</p>
      <p><b>How?</b><br>
            I've built a web scraper in python which dodges the current blocks on web scraping on Coles & Woolworths.<br>
            Alot of the old bots have been killed by Coles & Woolies who do not want people to get their data without visiting their website.<br>
          Coles & Woolies get alot of tracking data from users on their website and don't want them using 3rd party shopping websites or web scrapers<br><br>
        All data collection (scraping) is done overnight on Wednesday mornings as thats when specials & price changes are made</p>
      <p><b>Where are the files?</b><br>
            Files are hosted on Google Drive. Links to all files are on this page or if you prefer the google drive like is below.</p>
      <a href="https://drive.google.com/drive/folders/1-pnt5en_b8Tp93J-qcc09uJdtEX2ym3-?usp=sharing" >https://drive.google.com/drive/folders/1-pnt5en_b8Tp93J-qcc09uJdtEX2ym3-?usp=sharing</a>
      <p><b>Bugs / Bot Broken?</b><br>
        Report bugs at <b>aldipricebot@gmail.com</b> which forwards to my main email :D<br></p>
      <p><b>Question from Reddit: When does the bot update?</b><br>
        The bot will currently update the prices each Wednesday at 1am, which is when Coles and Woolies update their prices & specials.
        Links will link to most recent data and old price data will be stored in the google drive if you need it. Over the next few weeks the bot may run on other days for testing.</p>
    </section>
    <section id="coles">
      <h2 style="color: red;">Coles</h2>
      <p><b>Scope:</b><br>
            - Data collected from 1 store in the metro Brisbane Area<br>
            - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal groceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
            - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
            - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
            - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
            - Track all Coles stores prices. (Needs more funding as this will require lots of server time). There are 846 Coles stores in Aus<br>
            - Track Coles Local stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
      <a href="https://drive.google.com/uc?export=download&id=1Ls5FdaQxP9IoohxeVq6F129mNHOXodB_" download>Download COLES_TEST_DATA.csv<br></a>
      <p style="color: grey;">Download QLD_COLES_DATA.csv - Coming Soon!<br>
        Download NSW_COLES_DATA.csv - Coming Soon!<br>
        Download ACT_COLES_DATA.csv - Coming Soon!<br>
        Download NT_COLES_DATA.csv - Coming Soon!<br>
        Download WA_COLES_DATA.csv - Coming Soon!<br>
        Download SA_COLES_DATA.csv - Coming Soon!<br>
        Download TAS_COLES_DATA.csv - Coming Soon!<br>
        Download VIC_COLES_DATA.csv - Coming Soon!<br></p>

    </section>
    <section id="woolworths">
      <h2 style="color: rgb(78, 129, 2);">Woolworths</h2>
      <p><b>Scope:</b><br>
        - Data collected from 1 store in the metro Brisbane Area<br>
        - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal groceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
        - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
        - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
        - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
        - Track all Woolies stores prices. (Needs more funding as this will require lots of server time). There are ~1000 Woolies stores in Aus<br>
        - Track Woolies Metro stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
      <a href="https://drive.google.com/uc?export=download&id=1HQOy6v4EBafPocTYhdVvHTNwdUKBktRV" download>Download WOOLIES_TEST_DATA.csv<br></a>
      <p style="color: grey;">Download QLD_WOOLIES_DATA.csv - Coming Soon!<br>
        Download NSW_WOOLIES_DATA.csv - Coming Soon!<br>
        Download ACT_WOOLIES_DATA.csv - Coming Soon!<br>
        Download NT_WOOLIES_DATA.csv - Coming Soon!<br>
        Download WA_WOOLIES_DATA.csv - Coming Soon!<br>
        Download SA_WOOLIES_DATA.csv - Coming Soon!<br>
        Download TAS_WOOLIES_DATA.csv - Coming Soon!<br>
        Download VIC_WOOLIES_DATA.csv - Coming Soon!<br></p>
      <p><b>REPORTED BUG: Last night the bot had a network error which means not all of the woolworths data in 'cleaning section' was collected.</b></p>
    </section>
    <section id="kmart">
      <h2>Kmart</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="aldi">
      <h2>Aldi</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="bigw">
      <h2 style="color: rgb(42, 91, 225)">Big W</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="Donate">
      <h1 style="color: rgb(225, 42, 219)">Donate - Fund More Servers & Free Data</h1>
      <p>If you want to see more data & an expanded project consider donating to my ByMeACoffeeLink below. I only need small donations to expand the project.</p>
      <p><b>This project is not at all profitable and will only go towards upgrading servers to collect more data.</b>
      </p>
      <a href="https://www.buymeacoffee.com/max9753Hi" >Donate / ByMeACoffee</a>
    </section>
  </div>
</body>
</html>
