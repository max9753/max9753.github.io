<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AlexDiRobot</title>
<style>
  body {
    font-family: 'Arial', sans-serif;
    background-color: #ffffff;
    color: #000000;
    margin: 0;
    padding: 0;
  }
  .container {
    width: 80%;
    margin: auto;
    overflow: hidden;
  }
  header {
    background: #222;
    color: rgb(255, 255, 255);
    padding: 20px;
    text-align: center;
  }
  h2 {
    border-bottom: 1px solid #555;
    padding-bottom: 5px;
  }
  p {
    font-size: 16px;
    line-height: 1.6em;
  }
  section {
    margin: 20px 0;
  }
</style>
</head>
<body>
  <header>
    <h1>AlexDiBot<br>Groccery Prices Robot</h1>
  </header>
  <div class="container">
    <section id="what-is-this">
      <h2>What is this?</h2>
      <p>This is a robot that gets daily data from leading groccery shops for a University project.</p>
      <p><b>Why?</b><br>
      Some people (like me) prefer to make a budget using a spreadsheet and the website can be hard to navigate quickly and copy price info each week. This makes budgeting a breeze. Also this data is useful for tracking prices overtime.</p>
      <p>- Data is free and avaliable in CSV (can open this in excel or google sheets) file download.</p>
      <p>- API endpoints are coming soon.</p>
      <p><b>How?</b><br>
            I've built a web scraper in python which dodges the current blocks on web scraping on Coles & Woolworths.<br>
            Alot of the old bots have been killed by Coles & Woolies who do not want people to get their data without visiting their website.<br>
          Coles & Woolies get alot of tracking data from users on their website and don't want them using 3rd party shopping websites or web scrapers<br><br>
        All data collection (scraping) is done overnight on Wednesday mornings as thats when specials & price changes are made</p>
    </section>
    <section id="coles">
      <h2 style="color: red;">Coles</h2>
      <p><b>Scope:</b><br>
            - Data collected from 1 store in the metro Brisbane Area<br>
            - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal grocceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
            - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
            - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
            - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
            - Track all Coles stores prices. (Needs more funding as this will require lots of server time). There are 846 Coles stores in Aus<br>
            - Track Coles Local stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
      <a href="https://drive.google.com/uc?export=download&id=1HQOy6v4EBafPocTYhdVvHTNwdUKBktRV" download>Download COLES_TEST_DATA.csv<br></a>
      <p style="color: grey;">Download QLD_COLES_DATA.csv - Coming Soon!<br>
        Download NSW_COLES_DATA.csv - Coming Soon!<br>
        Download ACT_COLES_DATA.csv - Coming Soon!<br>
        Download NT_COLES_DATA.csv - Coming Soon!<br>
        Download WA_COLES_DATA.csv - Coming Soon!<br>
        Download SA_COLES_DATA.csv - Coming Soon!<br>
        Download TAS_COLES_DATA.csv - Coming Soon!<br>
        Download VIC_COLES_DATA.csv - Coming Soon!<br></p>

    </section>
    <section id="woolworths">
      <h2 style="color: rgb(78, 129, 2);">Woolworths</h2>
      <p><b>Scope:</b><br>
        - Data collected from 1 store in the metro Brisbane Area<br>
        - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal grocceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
        - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
        - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
        - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
        - Track all Woolies stores prices. (Needs more funding as this will require lots of server time). There are ~1000 Woolies stores in Aus<br>
        - Track Woolies Metro stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
      <a href="https://drive.google.com/uc?export=download&id=1HQOy6v4EBafPocTYhdVvHTNwdUKBktRV" download>Download WOOLIES_TEST_DATA.csv<br></a>
      <p style="color: grey;">Download QLD_WOOLIES_DATA.csv - Coming Soon!<br>
        Download NSW_WOOLIES_DATA.csv - Coming Soon!<br>
        Download ACT_WOOLIES_DATA.csv - Coming Soon!<br>
        Download NT_WOOLIES_DATA.csv - Coming Soon!<br>
        Download WA_WOOLIES_DATA.csv - Coming Soon!<br>
        Download SA_WOOLIES_DATA.csv - Coming Soon!<br>
        Download TAS_WOOLIES_DATA.csv - Coming Soon!<br>
        Download VIC_WOOLIES_DATA.csv - Coming Soon!<br></p>
    </section>
    <section id="kmart">
      <h2>Kmart</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="aldi">
      <h2>Aldi</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="bigw">
      <h2 style="color: rgb(42, 91, 225)">Big W</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="Donate">
      <h1 style="color: rgb(225, 42, 219)">Donate - Fund More Servers & Free Data</h1>
      <p>At the current scope I'm operating I don't require donors to keep going.</p>
      <p>Unfortunately I won't have the funds to scrape more than 7 stores (1 per state) total per week as it's fairly expensive</p>
      <p>Coles & Woolies do not like data collection like this which is why the bot will keep breaking & require constant weekly maintaince. But it will keep working as long as I'm doing my research for Uni</p>
      <p>Data is free but unfortunately the servers that run this bot are expensive.</p>
      <p>If you want to see more data & an expanded project consider donating to my ByMeACoffeeLink below. I only need small donations to expand the project.</p>
      <p><b>This project is not at all profitable and will only go towards upgrading servers to collect more data.</b>
      </p>
      <a href="https://www.buymeacoffee.com/max9753Hi" >Donate / ByMeACoffee</a>
    </section>
  </div>
</body>
</html>
