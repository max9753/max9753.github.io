<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AlexDiRobot</title>
<style>
  body {
    font-family: 'Arial', sans-serif;
    background-color: #ffffff;
    color: #000000;
    margin: 0;
    padding: 0;
  }
  .container {
    width: 80%;
    margin: auto;
    overflow: hidden;
  }
  header {
    background: #222;
    color: rgb(255, 255, 255);
    padding: 20px;
    text-align: center;
  }
  h2 {
    border-bottom: 1px solid #555;
    padding-bottom: 5px;
  }
  p {
    font-size: 16px;
    line-height: 1.6em;
  }
  section {
    margin: 20px 0;
  }
</style>
</head>
<body>
  <header>
    <h1>AlexDiBot<br>Grocery Prices Robot</h1>
  </header>
  <div class="container">
    <section id="what-is-this">
      <h2>What is this?</h2>
      <p>This is a robot that gets daily data from leading grocery shops for a University project. This website is not very pretty but is functional for now.</p>
      <p><b>Why?</b><br>
      Some people (like me) prefer to make a budget using a spreadsheet and the website can be hard to navigate quickly and copy price info each week. This makes budgeting a breeze. Also this data is useful for tracking prices overtime.</p>
      <p>- Data is free and avaliable in CSV (can open this in excel or google sheets) file download.</p>
      <p>- API endpoints are coming soon.</p>
      <p>- Bot will run long term and track groccery prices overtime
      <p>- Woolworths has ended support (by force) for normal data collection leaving alot of price comparison apps dead. This is an attempt to circumvent this.</p>
      </p>
      <p><b>How?</b><br>
            I've built a web scraper in python which dodges the current blocks on web scraping on Coles & Woolworths.<br>
            Alot of the old bots have been killed by Coles & Woolies who do not want people to get their data without visiting their website.<br>
          Coles & Woolies get alot of tracking data from users on their website and don't want them using 3rd party shopping websites or web scrapers<br><br>
        All data collection (scraping) is done overnight on Wednesday mornings as thats when specials & price changes are made</p>
      <p><b>Where are the files?</b><br>
            Files are hosted on Google Drive. Links to all files are on this page or if you prefer the google drive like is below.</p>
      <a href="https://drive.google.com/drive/folders/1-pnt5en_b8Tp93J-qcc09uJdtEX2ym3-?usp=sharing" >https://drive.google.com/drive/folders/1-pnt5en_b8Tp93J-qcc09uJdtEX2ym3-?usp=sharing</a>
      <p><b>Bugs / Bot Broken?</b><br>
        Report bugs at <b>aldipricebot@gmail.com</b> which forwards to my main email :D<br></p>
      <p><b>Question from Reddit: When does the bot update?</b><br>
        The bot will currently update the prices each Wednesday at 1am, which is when Coles and Woolies update their prices & specials.
        Links will link to most recent data and old price data will be stored in the google drive if you need it. Over the next few weeks the bot may run on other days for testing.</p>
    </section>
    <section id="coles">
      <h2 style="color: red;">Coles</h2>
      <p><b style="font-size: larger;">Changelog - Updated 01/12/23</b><br>
        - Added 1 data file per state<br>
        - Increased data collection and added new fields like "Product ID", "Unit Price", "Category", "Saving Amount", etc.<br>
        - Can now scrape any Coles store. But this requires a new instance of the bot each time a the moment. Email me if you want your store scraped and I will do it for you (for free) and publish it here.<br>
        - Currently still not scraping all stores as this would require lots of server time which I cannot afford.</p>
      <p><b>Scope:</b><br>
            - Data collected from 7 stores in Australia<br>
            - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal groceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
            - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
            - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
            - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
            - Track all Coles stores prices. (Needs more funding as this will require lots of server time). There are 846 Coles stores in Aus<br>
            - Track Coles Local stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
            <p><b>View Data</b><br>
            <a href="https://drive.google.com/drive/folders/1Q7aic5QrqrUF3civiWutdQNNqkhkN__U?usp=drive_link" >Coles Google Drive Folder - View & Download CSV Files</a>
      <p style="color: grey;">It was mentioned that people on phones could not download the csv files and view them.
        <br>I have removed the individual links in favor of the google drive folder link so that mobile users can see the product prices.<p>

    </section>
    <section id="woolworths">
      <h2 style="color: rgb(78, 129, 2);">Woolworths</h2>
      <p><b>Scope:</b><br>
        - Data collected from 1 store in the metro Brisbane Area<br>
        - From experimentaion, the only thing that often differs by state is fruit, vegetables & meat prices. Most normal groceries are nation wide priced. (Havn't checked extremely remote stores)</p>
      <p><b>Limitations:</b><br>
        - I can't currently afford (Uni Student) to pay for more server resources to scrape data from every store.<br>
        - This is very possible but expensive without donations.</p>
      <p><b>Planned Upgrades:</b><br>
        - Next week (hopefully) I will have seperate data for each state by getting data from 1 store in each capital.<br>
        - Track all Woolies stores prices. (Needs more funding as this will require lots of server time). There are ~1000 Woolies stores in Aus<br>
        - Track Woolies Metro stores (The more expensive but smaller stores). Again requires more funding to pay for servers</p>
        <p><b>View Data</b><br>
        <a href="https://drive.google.com/drive/folders/1ugYEgF-9q4WX0-mpWbqppfmZ9yGfpFFI?usp=drive_link" >Woolies Google Drive Folder - View & Download CSV Files</a>
        <p style="color: grey;">It was mentioned that people on phones could not download the csv files and view them.
          <br>I have removed the individual links in favor of the google drive folder link so that mobile users can see the product prices.<p>
    </section>
    <section id="kmart">
      <h2>Kmart</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="aldi">
      <h2>Aldi</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="bigw">
      <h2 style="color: rgb(42, 91, 225)">Big W</h2>
      <p><b>Coming Soon!</b></p>
    </section>
    <section id="Donate">
      <h1 style="color: rgb(225, 42, 219)">Donate - Fund More Servers & Free Data</h1>
      <p>If you want to see more data & an expanded project consider donating to my ByMeACoffeeLink below. I only need small donations to expand the project.</p>
      <p><b>This project is not at all profitable and will only go towards upgrading servers to collect more data.</b>
      </p>
      <a href="https://www.buymeacoffee.com/max9753Hi" >Donate / ByMeACoffee</a>
    </section>
  </div>
</body>
</html>
